{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530144c4",
   "metadata": {},
   "source": [
    "<h1><center>  lab 5 : Text Vectorization - Part 2 </center>\n",
    "    \n",
    "<img src=\"https://miro.medium.com/max/897/0*hcWVsMExgGQJWpt1\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7066e",
   "metadata": {},
   "source": [
    "```Created by Jinnie Shin (jinnie.shin@coe.ufl.edu)```\\\n",
    "```Date: ```\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQmNf86oJnfhpkPA9LnrFnAbfwF2VywPYpB_w&usqp=CAU\" align=\"left\" width=\"70\" height=\"70\" align=\"left\"> \n",
    "\n",
    " ### Required Packages or Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02eac3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jinnie.shin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jinnie.shin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jinnie.shin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install nbimporter #run this if you run into an error (download nbimporter)\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import nltk \n",
    "nltk.download(['punkt', 'wordnet', 'omw-1.4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aabe31",
   "metadata": {},
   "source": [
    "\n",
    "## **REVIEW**: Dataset\n",
    "\n",
    "> Using the text_normalizer function we created last time, we will import `essay set 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8288c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_normalize():\n",
    "    \n",
    "    def import_data(self, essay_set=3):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        self.essay_set = essay_set\n",
    "        self.data = []\n",
    "        self.score = []\n",
    "        filename = 'training_set_rel3.xlsx'\n",
    "        data = pd.read_excel(filename)\n",
    "        self.data  = data[data['essay_set']==self.essay_set].essay.values \n",
    "        self.score = data[data['essay_set']==self.essay_set].domain1_score.values \n",
    "       \n",
    "        return [' '.join(i) for i in self.data], pd.DataFrame(list(zip(self.data, self.score)), columns=['response', 'score'])\n",
    "    \n",
    "    def cleaning(self, string):\n",
    "        import re\n",
    "        string  = string.lower() # step 1. lowercase\n",
    "\n",
    "        punc = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~' # step 2. remove punctuations \n",
    "        string  = string.strip(punc) \n",
    "\n",
    "        string  = string.replace(\"can't\", 'cannot') # step 3. replace abbreviated forms \n",
    "        string = string.replace(\"n't\", ' not')\n",
    "        string  = string.replace(\"'ll\", ' will')\n",
    "        string  = string.replace(\"'m\", ' am')\n",
    "        string = string.replace(\"he's\", \"he is\")\n",
    "        string = string.replace(\"it's\", 'it is')\n",
    "\n",
    "        return re.sub(r\"\\d+\", \"<DIGIT>\", string) # step 4. replace all the numbers to <DIGIT>\n",
    "\n",
    "    def sent_tokenize(self, string):\n",
    "        import nltk\n",
    "        return nltk.sent_tokenize(string)\n",
    "    \n",
    "    def tokenize(self, string):\n",
    "        import nltk\n",
    "        return nltk.word_tokenize(string)\n",
    "\n",
    "    def stemming(self, tokens):\n",
    "        import nltk\n",
    "        stemmer = nltk.stem.PorterStemmer()\n",
    "        return [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    def lemmatize(self, tokens):\n",
    "        import nltk\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    def preprocess(self, essay_set=1):\n",
    "        _, self.df = self.import_data(essay_set=essay_set)\n",
    "        self.df['tokens'] = self.df.response.apply(self.tokenize)\n",
    "        self.df['sentences'] = self.df.response.apply(self.sent_tokenize)\n",
    "        self.df['stem'] = self.df.tokens.apply(self.stemming)\n",
    "        self.df['lemma'] = self.df.tokens.apply(self.lemmatize)\n",
    "\n",
    "        return self.df \n",
    "\n",
    "normalizer = text_normalize() # call the text_normalize function and name it normalizer\n",
    "\n",
    "df = normalizer.preprocess(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93263d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentences</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this memoir of Narciso Rodriguez, @PERSON3'...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[In, this, memoir, of, Narciso, Rodriguez, ,, ...</td>\n",
       "      <td>[In this memoir of Narciso Rodriguez, @PERSON3...</td>\n",
       "      <td>[in, thi, memoir, of, narciso, rodriguez, ,, @...</td>\n",
       "      <td>[In, this, memoir, of, Narciso, Rodriguez, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Throughout the excerpt from Home the Blueprint...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[Throughout, the, excerpt, from, Home, the, Bl...</td>\n",
       "      <td>[Throughout the excerpt from Home the Blueprin...</td>\n",
       "      <td>[throughout, the, excerpt, from, home, the, bl...</td>\n",
       "      <td>[Throughout, the, excerpt, from, Home, the, Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The mood the author created in the memoir is l...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[The, mood, the, author, created, in, the, mem...</td>\n",
       "      <td>[The mood the author created in the memoir is ...</td>\n",
       "      <td>[the, mood, the, author, creat, in, the, memoi...</td>\n",
       "      <td>[The, mood, the, author, created, in, the, mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mood created by the author is showing how ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[The, mood, created, by, the, author, is, show...</td>\n",
       "      <td>[The mood created by the author is showing how...</td>\n",
       "      <td>[the, mood, creat, by, the, author, is, show, ...</td>\n",
       "      <td>[The, mood, created, by, the, author, is, show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mood created in the memoir is happiness an...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[The, mood, created, in, the, memoir, is, happ...</td>\n",
       "      <td>[The mood created in the memoir is happiness a...</td>\n",
       "      <td>[the, mood, creat, in, the, memoir, is, happi,...</td>\n",
       "      <td>[The, mood, created, in, the, memoir, is, happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>The mood of this memoir is nonfiction. The moo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[The, mood, of, this, memoir, is, nonfiction, ...</td>\n",
       "      <td>[The mood of this memoir is nonfiction., The m...</td>\n",
       "      <td>[the, mood, of, thi, memoir, is, nonfict, ., t...</td>\n",
       "      <td>[The, mood, of, this, memoir, is, nonfiction, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>The mood was created by the author in the memo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[The, mood, was, created, by, the, author, in,...</td>\n",
       "      <td>[The mood was created by the author in the mem...</td>\n",
       "      <td>[the, mood, wa, creat, by, the, author, in, th...</td>\n",
       "      <td>[The, mood, wa, created, by, the, author, in, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>In the memoir \"Narciso Rodriguez\", the mood cr...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[In, the, memoir, ``, Narciso, Rodriguez, '', ...</td>\n",
       "      <td>[In the memoir \"Narciso Rodriguez\", the mood c...</td>\n",
       "      <td>[in, the, memoir, ``, narciso, rodriguez, '', ...</td>\n",
       "      <td>[In, the, memoir, ``, Narciso, Rodriguez, '', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>The mood created @CAPS3 the author, Narciso Ro...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[The, mood, created, @, CAPS3, the, author, ,,...</td>\n",
       "      <td>[The mood created @CAPS3 the author, Narciso R...</td>\n",
       "      <td>[the, mood, creat, @, caps3, the, author, ,, n...</td>\n",
       "      <td>[The, mood, created, @, CAPS3, the, author, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>The author created such a specific mood for th...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[The, author, created, such, a, specific, mood...</td>\n",
       "      <td>[The author created such a specific mood for t...</td>\n",
       "      <td>[the, author, creat, such, a, specif, mood, fo...</td>\n",
       "      <td>[The, author, created, such, a, specific, mood...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1805 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               response  score  \\\n",
       "0     In this memoir of Narciso Rodriguez, @PERSON3'...    2.0   \n",
       "1     Throughout the excerpt from Home the Blueprint...    2.0   \n",
       "2     The mood the author created in the memoir is l...    3.0   \n",
       "3     The mood created by the author is showing how ...    1.0   \n",
       "4     The mood created in the memoir is happiness an...    3.0   \n",
       "...                                                 ...    ...   \n",
       "1800  The mood of this memoir is nonfiction. The moo...    2.0   \n",
       "1801  The mood was created by the author in the memo...    0.0   \n",
       "1802  In the memoir \"Narciso Rodriguez\", the mood cr...    4.0   \n",
       "1803  The mood created @CAPS3 the author, Narciso Ro...    3.0   \n",
       "1804  The author created such a specific mood for th...    2.0   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [In, this, memoir, of, Narciso, Rodriguez, ,, ...   \n",
       "1     [Throughout, the, excerpt, from, Home, the, Bl...   \n",
       "2     [The, mood, the, author, created, in, the, mem...   \n",
       "3     [The, mood, created, by, the, author, is, show...   \n",
       "4     [The, mood, created, in, the, memoir, is, happ...   \n",
       "...                                                 ...   \n",
       "1800  [The, mood, of, this, memoir, is, nonfiction, ...   \n",
       "1801  [The, mood, was, created, by, the, author, in,...   \n",
       "1802  [In, the, memoir, ``, Narciso, Rodriguez, '', ...   \n",
       "1803  [The, mood, created, @, CAPS3, the, author, ,,...   \n",
       "1804  [The, author, created, such, a, specific, mood...   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     [In this memoir of Narciso Rodriguez, @PERSON3...   \n",
       "1     [Throughout the excerpt from Home the Blueprin...   \n",
       "2     [The mood the author created in the memoir is ...   \n",
       "3     [The mood created by the author is showing how...   \n",
       "4     [The mood created in the memoir is happiness a...   \n",
       "...                                                 ...   \n",
       "1800  [The mood of this memoir is nonfiction., The m...   \n",
       "1801  [The mood was created by the author in the mem...   \n",
       "1802  [In the memoir \"Narciso Rodriguez\", the mood c...   \n",
       "1803  [The mood created @CAPS3 the author, Narciso R...   \n",
       "1804  [The author created such a specific mood for t...   \n",
       "\n",
       "                                                   stem  \\\n",
       "0     [in, thi, memoir, of, narciso, rodriguez, ,, @...   \n",
       "1     [throughout, the, excerpt, from, home, the, bl...   \n",
       "2     [the, mood, the, author, creat, in, the, memoi...   \n",
       "3     [the, mood, creat, by, the, author, is, show, ...   \n",
       "4     [the, mood, creat, in, the, memoir, is, happi,...   \n",
       "...                                                 ...   \n",
       "1800  [the, mood, of, thi, memoir, is, nonfict, ., t...   \n",
       "1801  [the, mood, wa, creat, by, the, author, in, th...   \n",
       "1802  [in, the, memoir, ``, narciso, rodriguez, '', ...   \n",
       "1803  [the, mood, creat, @, caps3, the, author, ,, n...   \n",
       "1804  [the, author, creat, such, a, specif, mood, fo...   \n",
       "\n",
       "                                                  lemma  \n",
       "0     [In, this, memoir, of, Narciso, Rodriguez, ,, ...  \n",
       "1     [Throughout, the, excerpt, from, Home, the, Bl...  \n",
       "2     [The, mood, the, author, created, in, the, mem...  \n",
       "3     [The, mood, created, by, the, author, is, show...  \n",
       "4     [The, mood, created, in, the, memoir, is, happ...  \n",
       "...                                                 ...  \n",
       "1800  [The, mood, of, this, memoir, is, nonfiction, ...  \n",
       "1801  [The, mood, wa, created, by, the, author, in, ...  \n",
       "1802  [In, the, memoir, ``, Narciso, Rodriguez, '', ...  \n",
       "1803  [The, mood, created, @, CAPS3, the, author, ,,...  \n",
       "1804  [The, author, created, such, a, specific, mood...  \n",
       "\n",
       "[1805 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62905d5",
   "metadata": {},
   "source": [
    "## 1. Skip-gram (Word2Vec) shortcut using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b033f101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['In', 'this', 'memoir', 'of', 'Narciso', 'Rodriguez', ',', '@', 'PERSON3', \"'s\", 'life', ',', 'the', 'mood', 'containing', 'it', 'all', ',', 'was', 'greatful', ',', 'and', 'showed', 'how', 'his', 'parents', 'gave', 'him', 'love', 'through', 'his', 'whole', 'life', '.', 'Both', 'his', 'parents', 'were', 'born', 'and', 'raised', 'in', 'Cuba', ',', 'and', 'in', '1956', ',', 'they', 'both', 'moved', 'to', 'the', 'United', 'States', '.', 'Starting', 'their', 'lives', 'over', 'again', ',', 'and', 'taking', 'any', 'job', 'they', 'could', 'find', '.', 'Then', 'in', '1961', ',', '@', 'PERSON2', ',', '@', 'CAPS1', '.', 'was', 'born', '.', 'Both', 'Parents', 'raised', 'him', 'with', 'love', ',', 'and', 'care', ',', 'and', 'introducing', 'his', 'Cuban', 'background', 'into', 'his', 'life', '.', 'As', '@', 'PERSON2', ',', 'was', 'telling', 'his', 'story', ',', 'all', 'readers', 'could', 'tell', 'how', 'greatful', 'he', 'was', 'to', 'have', 'a', 'family', 'like', 'he', 'did', '.', 'Also', ',', 'as', 'he', 'shared', 'his', 'non-–', 'blood', 'related', 'family', ',', 'and', 'the', 'remembrence', 'on', 'how', 'his', 'parents', \"'\", 'life', 'changed', 'by', 'moving', 'to', '@', 'LOCATION2', ',', 'he', 'showed', 'the', 'respect', 'he', 'had', 'towards', 'them', '.'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04510524,  0.26697066,  0.26178637, -0.09336256,  0.7100486 ,\n",
       "       -0.50711715,  0.27854463,  0.41906863, -0.29762545,  0.09513719,\n",
       "       -0.498547  , -0.48606616, -0.16202459, -0.31114635,  0.02056565,\n",
       "        0.5335748 ,  0.46839586,  0.6353834 , -1.076645  , -0.5750287 ,\n",
       "        0.7170416 ,  0.5854732 ,  0.07437601, -0.04927132,  0.29328343,\n",
       "        0.2701225 ,  0.50601614, -0.65855676, -0.07047258, -0.22207823,\n",
       "        0.05423851,  0.48059362,  0.21850856,  0.2510585 ,  0.13848186,\n",
       "        0.53914315,  0.93614185, -0.06313057,  0.00417231,  0.0094842 ,\n",
       "        0.52310115, -0.03271529, -0.4822553 , -0.20599154,  1.342623  ,\n",
       "       -0.00356475, -0.59507424, -0.388651  ,  0.29877394,  0.42734957],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "token_list = df['tokens'].values# this has to be a list that saves all the vocabulary \n",
    "\n",
    "print(token_list[:1])\n",
    "\n",
    "model = Word2Vec(token_list, min_count=1,vector_size= 50,workers=3, window =2, sg = 1) # this is your model\n",
    "# > vector_size: The number of dimensions of the embeddings and the default is 100.\n",
    "# > window: The maximum distance between a target word and words around the target word. The default window is 5.\n",
    "# > min_count: The minimum count of words to consider when training the model; words with occurrence less than this count will be ignored. The default for min_count is 5.\n",
    "# > workers: The number of partitions during training and the default workers is 3.\n",
    "# > sg: The training algorithm, either CBOW(0) or skip gram(1). The default training algorithm is CBOW.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore\n",
    "\n",
    "print(model.wv['author']) #this is to see the vector of a particular word \n",
    "print(model.wv['the'])\n",
    "\n",
    "# dimension of the embeddings? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5da30823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore\n",
    "\n",
    "#model.wv.most_similar('your token here') # to get the list of most similar tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2dfc6ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Throughout', 'the', 'excerpt', 'from', 'Home', 'the', 'Blueprints', 'of', 'Our', 'Lives', ',', 'Narciso', 'Rodriguez', ',', 'the', 'author', ',', 'manages', 'to', 'maintain', 'a', 'single', 'overall', 'mood', '.', 'In', 'many', 'parts', 'of', 'the', 'story', 'he', 'tells', 'about', 'how', 'much', 'he', 'loved', 'his', 'childhood', 'so', 'it', 'lead', 'me', 'to', 'think', 'was', 'nostalgia', ',', 'but', 'nowhere', 'does', 'it', 'emphasize', 'that', 'he', 'yearns', 'to', 'return', 'to', 'past', 'times', '.', 'He', 'always', 'declared', 'how', 'loving', 'and', 'selfless', 'his', 'family', 'was', ',', 'how', 'they', 'aided', 'others', ',', 'and', 'how', 'he', 'became', \"''\", 'family', \"''\", 'with', 'his', 'neighbors', '.', 'Due', 'to', 'this', 'I', 'have', 'found', 'the', 'tone', 'to', 'be', ',', 'loving', 'and', 'admiring', 'towards', 'his', 'parents', '.', 'This', 'is', 'so', 'due', 'to', 'the', 'fact', 'that', 'he', 'states', 'how', 'his', 'parents', 'were', 'so', 'brave', 'to', 'leave', 'their', 'lives', 'in', 'Cuba', 'behind', 'just', 'so', 'he', 'could', 'have', 'a', 'better', 'life', '.', 'Narciso', 'Rodriguez', 'also', 'remarks', 'numerous', 'times', 'on', 'how', 'his', 'parents', 'helped', 'so', 'many', 'in', 'need', '.', 'If', 'in', 'Rodriguez', \"'s\", 'position', 'I', 'would', 'love', 'and', 'admire', 'my', 'parents', 'just', 'as', 'much', ',', 'if', 'not', 'more', ',', 'for', 'their', 'selfless', 'deeds', 'and', 'upbringing', 'of', 'their', 'son', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.09283703,  0.22092739,  0.08713946,  0.1767992 , -0.0684889 ,\n",
       "       -0.32384235,  0.39595193,  0.56346333, -0.3686944 , -0.25329593,\n",
       "        0.09150464, -0.43500766,  0.26115996,  0.13579236, -0.16134955,\n",
       "        0.4430558 ,  0.40166396,  0.21252805, -0.43450668, -0.38708115,\n",
       "        0.29850265,  0.46404812,  0.48952582, -0.00839027,  0.24992566,\n",
       "        0.08442023,  0.01655283,  0.30153635, -0.2995487 ,  0.01725363,\n",
       "        0.17147624, -0.21141139, -0.1303362 , -0.08280358, -0.03882691,\n",
       "        0.20229356,  0.47468904,  0.15692674,  0.16440259, -0.21245219,\n",
       "        0.4369847 , -0.19086793, -0.03272782, -0.13134383,  0.61550456,\n",
       "        0.00832669,  0.03070776, -0.3663987 ,  0.20016785,  0.19245735],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's explore \n",
    "\n",
    "# >> How to represent this essay into a vector then? \n",
    "\n",
    "example_essay = df.iloc[1].tokens\n",
    "print(example_essay)\n",
    "\n",
    "############ YOUR RESPONSE HERE ##################\n",
    "\n",
    "#HINT: model.wv[example_essay[0]] This will give the embedding for the first token of the document \n",
    "\n",
    "result = [model.wv[i] for i in example_essay]\n",
    "np.mean(result, axis=0)\n",
    "\n",
    "##################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca86fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def average_embedding(model, document):\n",
    "    normalizer = text_normalize()\n",
    "    tokens = normalizer.tokenize(document )\n",
    "  \n",
    "    result = [model.wv[i] for i in tokens]\n",
    "    \n",
    "    return np.mean(result, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "154442cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09283703,  0.22092739,  0.08713946,  0.1767992 , -0.0684889 ,\n",
       "       -0.32384235,  0.39595193,  0.56346333, -0.3686944 , -0.25329593,\n",
       "        0.09150464, -0.43500766,  0.26115996,  0.13579236, -0.16134955,\n",
       "        0.4430558 ,  0.40166396,  0.21252805, -0.43450668, -0.38708115,\n",
       "        0.29850265,  0.46404812,  0.48952582, -0.00839027,  0.24992566,\n",
       "        0.08442023,  0.01655283,  0.30153635, -0.2995487 ,  0.01725363,\n",
       "        0.17147624, -0.21141139, -0.1303362 , -0.08280358, -0.03882691,\n",
       "        0.20229356,  0.47468904,  0.15692674,  0.16440259, -0.21245219,\n",
       "        0.4369847 , -0.19086793, -0.03272782, -0.13134383,  0.61550456,\n",
       "        0.00832669,  0.03070776, -0.3663987 ,  0.20016785,  0.19245735],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's explore your answer \n",
    "essay = df.response.values[2]\n",
    "\n",
    "average_embedding(model, essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "892a6ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"In this memoir of Narciso Rodriguez, @PERSON3's life, the mood containing it all, was greatful, and showed how his parents gave him love through his whole life. Both his parents were born and raised in Cuba, and in 1956, they both moved to the United States. Starting their lives over again, and taking any job they could find. Then in 1961, @PERSON2, @CAPS1. was born. Both Parents raised him with love, and care, and introducing his Cuban background into his life.        As @PERSON2, was telling his story, all readers could tell how greatful he was to have a family like he did. Also, as he shared his non-– blood related family, and the remembrence on how his parents' life changed by moving to @LOCATION2, he showed the respect he had towards them.\"\n",
      " 'Throughout the excerpt from Home the Blueprints of Our Lives, Narciso Rodriguez, the author, manages to maintain a single overall mood. In many parts of the story he tells about how much he loved his childhood so it lead me to think was nostalgia, but nowhere does it emphasize that he yearns to return to past times. He always declared how loving and selfless his family was, how they aided others, and how he became\" family\" with his neighbors. Due to this I have found the tone to be, loving and admiring towards his parents. This is so due to the fact that he states how his parents were so brave to leave their lives in Cuba behind just so he could have a better life. Narciso Rodriguez also remarks numerous times on how his parents helped so many in need. If in Rodriguez\\'s position I would love and admire my parents just as much, if not more, for their selfless deeds and upbringing of their son.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99065447]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compare_similarity(documents):\n",
    "    \n",
    "    # use the average_embedding function you created above and a for-loop or a while-loop\n",
    "    # to create a list called `embeddings`\n",
    "    embeddings = []\n",
    "    \n",
    "    ############### your code here ##################\n",
    "    for document in documents:\n",
    "        embedding = average_embedding(model, document)\n",
    "        embeddings.append([embedding])\n",
    "    ################################################\n",
    "    \n",
    "    # compute the cosine similarity score of all pairs of the document list\n",
    "    from itertools import combinations # you can use the combinations function \n",
    "    sim=0\n",
    "    pairs = list(combinations(embeddings, 2))\n",
    "    \n",
    "    ############### your code here ##################\n",
    "    for pair in pairs: \n",
    "        value = cosine_similarity(pair[0], pair[1])\n",
    "        sim+=value\n",
    "    \n",
    "    ################################################\n",
    "    return sim/len(pairs)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# let's explore\n",
    "essays = df.response.values[:2]\n",
    "print(essays)\n",
    "\n",
    "compare_similarity(essays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e7c62",
   "metadata": {},
   "source": [
    "## 4. Pre-trained GloVe Embeddings \n",
    "> Glove pre-trained word vectors are trained based on 6B tokens (400k vocabs) using Wikipedia 2014 and Gigaword 5. Various dimensions are availble (50d, 100d, 200d, & 300d).\n",
    "More information avaialble at : https://nlp.stanford.edu/projects/glove/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4a76d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class glove_embedding():\n",
    "   \n",
    "    def embedding(self, input_dir='./'):\n",
    "        self.embeddings_index= []\n",
    "        self.word_id = {}\n",
    "        self.embeddings_index.append([0]*50)\n",
    "        count=1\n",
    "        f = open(input_dir+ 'glove.6B.50d.txt', encoding= 'utf8')\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs =np.asarray(values[1:], dtype='float32') \n",
    "            self.word_id[word]= count\n",
    "            self.embeddings_index.append(coefs) \n",
    "            count +=1\n",
    "        f.close()\n",
    "\n",
    "    def look_up(self, word):\n",
    "        try: \n",
    "            word_id = self.word_id[word]\n",
    "        \n",
    "            return self.embeddings_index[word_id]\n",
    "       \n",
    "        except KeyError:\n",
    "             print(\"Oops!  OOV.  Try again...\")\n",
    "            \n",
    "    \n",
    "glove = glove_embedding()\n",
    "glove.embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad4ffc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51278 ,  0.25157 , -0.18394 , -0.014212,  0.98777 ,  0.67637 ,\n",
       "        1.4479  , -0.69126 ,  0.42395 ,  0.98987 ,  0.52666 ,  0.47261 ,\n",
       "        0.10964 ,  0.57513 ,  0.71705 ,  0.43191 ,  0.74033 ,  0.064138,\n",
       "        0.6063  ,  0.88668 ,  0.45273 , -1.3187  ,  0.85178 ,  1.436   ,\n",
       "       -0.85848 ,  0.15967 ,  0.57879 , -0.33475 ,  0.063739, -0.39744 ,\n",
       "       -0.53869 , -1.198   , -0.78489 ,  0.62126 ,  1.5683  ,  0.35829 ,\n",
       "        0.23824 , -0.17746 , -0.8014  ,  1.1288  ,  0.87474 , -0.25988 ,\n",
       "        0.47701 ,  0.17045 , -0.18032 , -0.41559 ,  1.1162  ,  0.75873 ,\n",
       "       -0.071018, -0.32746 ], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.look_up('trna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b969a0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oops!  OOV.  Try again...\n"
     ]
    }
   ],
   "source": [
    "glove.look_up('grna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cedbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
